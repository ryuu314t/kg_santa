{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本変数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_flg=0 #サンプリング有無をコントロール\n",
    "submit_flg=1 #保存するかをコントロール（サンプリングしない時のみ）\n",
    "\n",
    "SEED=12345\n",
    "sample_num=10000\n",
    "fold_num=5\n",
    "\n",
    "#train関連\n",
    "train_dir='../../02_feature/101_train.csv'\n",
    "train_drop_col=['ID_code', 'target']\n",
    "train_label='target'\n",
    "\n",
    "#test関連\n",
    "test_dir='../../02_feature/101_test.csv'\n",
    "test_drop_col=['ID_code']\n",
    "\n",
    "#結果ファイル関連　nameは自分の名前に変更する\n",
    "train_preds_dir='../../03_predict_train/oka_243_LightGBM_train.csv'\n",
    "test_preds_dir='../../04_predict_test/oka_243_LightGBM_submission.csv'\n",
    "save_col_name='oof_xgb'\n",
    "\n",
    "sample_submission_dir='../../01_input/sample_submission.csv'\n",
    "submission_target_col_name='target'\n",
    "submission_id_col_name='ID_code'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ロード\n",
    "train_df=pd.read_csv(train_dir)\n",
    "test_df=pd.read_csv(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#サンプリング\n",
    "if sampling_flg ==1:\n",
    "    train_df=train_df.sample(n=sample_num,random_state=SEED)\n",
    "    test_df=test_df.sample(n=sample_num,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y作成\n",
    "x_train=train_df.drop(train_drop_col,axis=1)\n",
    "y_train=train_df[train_label]\n",
    "x_test=test_df.drop(test_drop_col,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_param\n",
    "param = {\n",
    "    \"objective\" : \"binary\", \n",
    "    \"boost\":\"gbdt\",\n",
    "    \"metric\":\"auc\",\n",
    "    \"boost_from_average\":\"false\",\n",
    "    \"num_threads\":28,\n",
    "    \"learning_rate\" : 0.01,\n",
    "    \"num_leaves\" : 13,\n",
    "    \"max_depth\":-1,\n",
    "    \"tree_learner\" : \"serial\",\n",
    "    \"feature_fraction\" : 0.05,\n",
    "    \"bagging_freq\" : 5,\n",
    "    \"bagging_fraction\" : 0.4,\n",
    "    \"min_data_in_leaf\" : 80,\n",
    "    \"min_sum_hessian_in_leaf\" : 10.0,\n",
    "    \"verbosity\" : 1,\n",
    "    'seed': 44000,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=300,\n",
    "                               tol=0.0001,precompute_distances='auto', verbose=0,\n",
    "                               random_state=11111, copy_x=True, n_jobs=1)\n",
    "clf.fit(x_train)\n",
    "pred=clf.predict(x_test)\n",
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kmean(in_trn_x,in_val_x,in_test_x):\n",
    "    print(in_test_x.shape)\n",
    "    new_trn=in_trn_x\n",
    "    new_val=in_val_x\n",
    "    new_test=in_test_x\n",
    "    for i in range(2,20):\n",
    "        print(i)\n",
    "        clf=KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=300,\n",
    "                               tol=0.0001,precompute_distances='auto', verbose=0,\n",
    "                               random_state=11111, copy_x=True, n_jobs=1)\n",
    "        clf.fit(in_trn_x)\n",
    "        pred=clf.predict(in_trn_x)\n",
    "        new_trn['kmeans_'+str(i)]=pred\n",
    "        pred=clf.predict(in_val_x)\n",
    "        new_val['kmeans_'+str(i)]=pred\n",
    "        pred=clf.predict(in_test_x)\n",
    "        new_test['kmeans_'+str(i)]=pred\n",
    "        \n",
    "    return new_trn,new_val,new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Unnamed: 0    var_0    var_1    var_2    var_3    var_4    var_5  \\\n",
       "0                0  11.0656   7.7798  12.9536   9.4292  11.4327  -2.3805   \n",
       "1                1   8.5304   1.2543  11.3047   5.1858   9.1974  -4.0117   \n",
       "2                2   5.4827 -10.3581  10.1407   7.0479  10.2628   9.8052   \n",
       "3                3   8.5374  -1.3222  12.0220   6.5749   8.8458   3.1744   \n",
       "4                4  11.7058  -0.1327  14.1295   7.7506   9.1035  -8.5848   \n",
       "5                5   5.9862  -2.2913   8.6058   7.0685  14.2465  -8.6761   \n",
       "6                6   8.4624  -6.1065   7.3603   8.2627  12.0104  -7.2073   \n",
       "7                7  17.3035  -2.4212  13.3989   8.3998  11.0777   9.6449   \n",
       "8                8   6.9856   0.8402  13.7161   4.7749   8.6784 -13.7607   \n",
       "9                9  10.3811  -6.9348  14.6690   9.0941  11.9058 -10.8018   \n",
       "10              10   8.3431  -4.1427   9.1985   9.8229  11.2494   2.9678   \n",
       "11              11  10.6137  -2.1898   8.9090   3.8014  13.8602  -5.9802   \n",
       "12              12  12.7465  -4.9467  15.5490   6.4580  13.7572 -25.5371   \n",
       "13              13  11.7836   1.9979  10.3347   7.8857  13.1020   5.0167   \n",
       "14              14   7.0360   1.6797   9.3865   3.2605  10.7569  -8.0802   \n",
       "15              15  14.8595  -4.5378  13.6483   5.6480   9.9144   1.5190   \n",
       "16              16  14.1732  -5.1490   9.7591   3.7316  10.3700 -21.9202   \n",
       "17              17   9.0936  -8.7414  17.1160   6.0126   9.2144  -3.6761   \n",
       "18              18  15.7875   0.1671  10.7782   3.8521   9.1190  11.0196   \n",
       "19              19  13.3874   1.0716   8.8767   7.8374  11.6404   6.2512   \n",
       "20              20   8.0259  -4.6740   8.6431   2.2198  11.4555 -14.0227   \n",
       "21              21  14.3356   0.2317   9.5604   5.7603  10.3184  -6.4721   \n",
       "22              22  10.4255  -6.1758  12.4846   7.9845   9.7032 -14.5969   \n",
       "23              23  12.3322  -6.3835   7.2471   5.0403  10.0875  -1.5252   \n",
       "24              24  14.1844  -9.1044   9.7453   9.2638   9.3302   2.6818   \n",
       "25              25  10.0029   0.2530   7.5335   6.9343  11.6866  -6.5147   \n",
       "26              26   6.9056  -4.8626  11.8932   5.3693  11.2551 -18.9716   \n",
       "27              27   8.7562  -3.0647  11.7990   9.2162  10.9847 -22.4902   \n",
       "28              28   9.7243  -1.5151  11.5582   5.7360  12.1907   6.9664   \n",
       "29              29  13.2430   1.2738  10.4245   3.1863  11.4951  -1.4755   \n",
       "...            ...      ...      ...      ...      ...      ...      ...   \n",
       "199970      199970  12.7260  -1.6706  12.3598   9.1114  10.1868  -9.5857   \n",
       "199971      199971   9.4700  -6.7655  12.6591   9.1842  11.8260   0.0264   \n",
       "199972      199972  13.3243   1.0870   8.4555   3.6929  11.2423   1.3986   \n",
       "199973      199973  14.2830  -1.8421  11.3664   8.5772   8.8645 -13.8986   \n",
       "199974      199974   4.5171  -5.2068   7.6007   8.1426  10.4433 -17.2322   \n",
       "199975      199975  13.4796   2.7000  10.9653   9.1581  13.2959  -3.0995   \n",
       "199976      199976  12.6337  -6.9793   9.8703   9.9180  10.8092   2.5809   \n",
       "199977      199977  10.8078  -4.6108   9.0021   9.8910  12.4514  -3.7566   \n",
       "199978      199978   9.9317  -2.2815  11.1707   5.6826  12.7396  -4.0659   \n",
       "199979      199979  10.5933  -1.2672  13.6817   6.3789  12.8649  -5.4964   \n",
       "199980      199980  13.4136   5.3912   9.6202   8.5025  12.0951  11.3431   \n",
       "199981      199981   7.9218  -5.7464  11.4171   6.7972  11.6260  -8.7730   \n",
       "199982      199982   7.2189   1.6606  10.4651   4.4382  10.5562  -5.2083   \n",
       "199983      199983  11.8527   5.4321  12.7268  10.2392  12.4740 -14.6939   \n",
       "199984      199984  12.7445  -6.1135   9.9046   7.5790  14.8852   4.5083   \n",
       "199985      199985  14.8983   2.1302   7.4747   7.1744  11.8252  13.1758   \n",
       "199986      199986  19.2884  -2.8384  11.9149   6.6611  12.3112  12.9244   \n",
       "199987      199987  11.2942   3.6321  15.3300   6.6904  10.9223  -5.6537   \n",
       "199988      199988   6.4535  -2.1707  10.7623   8.1571   7.9365   4.6091   \n",
       "199989      199989   9.0436  -3.0491  10.8737   7.8789  11.0275 -10.1812   \n",
       "199990      199990   5.5416   1.7340   9.6938   5.0126  11.3049 -15.9906   \n",
       "199991      199991   8.7935  -4.0646   9.9480   8.6947  11.0497  -0.5129   \n",
       "199992      199992  16.4229  -5.0254  13.1385   5.4599  13.1347  -2.6212   \n",
       "199993      199993  14.6764  -8.1066   7.1167   2.4138  10.3845 -11.9327   \n",
       "199994      199994   8.2964  -2.3119  11.2139   9.1357   8.5339   4.0350   \n",
       "199995      199995  13.1678   1.0136  10.4333   6.7997   8.5974  -4.1641   \n",
       "199996      199996   9.7171  -9.1462   7.3443   9.1421  12.8936   3.0191   \n",
       "199997      199997  11.6360   2.2769  11.2074   7.7649  12.6796  11.3224   \n",
       "199998      199998  13.5745  -0.5134  13.6584   7.4855  11.2241 -11.3037   \n",
       "199999      199999  10.4664   1.8070  10.2277   6.0654  10.0258   1.0789   \n",
       "\n",
       "         var_6    var_7   var_8   ...     var_190  var_191  var_192  var_193  \\\n",
       "0       5.8493  18.2675  2.1337   ...     -2.1556  11.8495  -1.4300   2.4508   \n",
       "1       6.0196  18.6316 -4.4131   ...     10.6165   8.8349   0.9403  10.1282   \n",
       "2       4.8950  20.2537  1.5233   ...     -0.7484  10.9935   1.9803   2.1800   \n",
       "3       4.9397  20.5660  3.3755   ...      9.5702   9.0766   1.6580   3.5813   \n",
       "4       6.8595  10.6048  2.9890   ...      4.2259   9.1723   1.2835   3.3778   \n",
       "5       4.2467  14.7632  1.8790   ...     -2.1115   7.1178  -0.4249   8.8781   \n",
       "6       4.1670  13.0809 -4.3004   ...     12.3609   6.8661   4.0971   8.8484   \n",
       "7       5.9596  17.8477 -4.8068   ...      4.4676   4.4214   0.9303   1.4994   \n",
       "8       4.3386  14.5843  2.5883   ...     -3.4657   7.8754   2.4698  -0.0362   \n",
       "9       3.4508  20.2816 -1.4112   ...      1.8052  11.0723   0.8907   4.7680   \n",
       "10      5.5184  15.6290  2.8032   ...      1.9040   6.7916   0.5810  -2.1353   \n",
       "11      5.5515  15.4716 -0.1714   ...     13.1683   4.0625  -0.1537   7.9787   \n",
       "12      4.4893  15.1682  3.1754   ...      7.8803   4.3879   1.9888  -0.6670   \n",
       "13      4.9548  23.6527  3.5911   ...      2.9624   7.3561   3.2395   3.9152   \n",
       "14      4.7885  15.0583  0.6459   ...     -0.7003   3.0835   2.7034   0.9803   \n",
       "15      5.0358  13.4524 -2.5419   ...      2.6735   5.8526   4.8517   2.5020   \n",
       "16      7.7130  18.8749  0.4680   ...      0.8640   5.9058   1.3140   4.8961   \n",
       "17      4.6477  20.1053  1.7687   ...      6.6018   7.7219   0.4559   2.7977   \n",
       "18      6.1113  18.4368 -1.0728   ...      6.7408  13.1753   0.2111   6.6279   \n",
       "19      4.8837  18.2178  4.3871   ...     -2.2262  11.8869   1.6137   4.7306   \n",
       "20      6.9192  17.8559  0.4283   ...     -0.6869   3.9088  -0.2736   5.4434   \n",
       "21      4.6898  13.7783  1.8342   ...     10.5084   6.8724   1.5538   4.6148   \n",
       "22      4.4173  19.3606 -0.5899   ...      7.7860   4.7884   5.0819  -5.1081   \n",
       "23      5.8230  17.9494 -3.8454   ...      2.2038  11.1389   1.4025  -0.4134   \n",
       "24      5.4711  18.5414  2.2065   ...      4.9466   9.4174   0.7743   4.5556   \n",
       "25      6.7327  19.8941 -6.6497   ...     -2.1072   5.1404   1.2851   2.2366   \n",
       "26      5.5991  18.9809  5.5612   ...     -0.7638   6.7125   0.3169   6.0765   \n",
       "27      4.2991  13.9800  3.3233   ...     -0.7497   4.7817   1.3885  -1.3448   \n",
       "28      4.4125  17.4770 -3.9683   ...      6.4360  11.2645   3.1891  -0.0828   \n",
       "29      5.1005  17.1687  1.7115   ...     -2.3786   7.8381   0.9822   2.2038   \n",
       "...        ...      ...     ...   ...         ...      ...      ...      ...   \n",
       "199970  5.3494  23.6362  2.0626   ...     10.6793   9.5029  -0.1536   1.9221   \n",
       "199971  5.0633  20.7034  2.4171   ...      4.4258  11.5775   1.4309   8.0710   \n",
       "199972  4.4765  19.1021 -2.6573   ...     -0.3722   9.2868   3.1847   8.8422   \n",
       "199973  4.1603  19.4591  5.6445   ...      5.5744   9.2002   3.3686   6.2250   \n",
       "199974  4.4205  20.3407 -1.0196   ...     -0.3355   3.4422   3.0645   1.2469   \n",
       "199975  5.1483  20.9766  1.2932   ...      4.0747   4.1240   2.5431   6.2910   \n",
       "199976  6.7764  18.3443  4.1498   ...      2.7140  11.0722   1.2368   0.6363   \n",
       "199977  4.2958  19.9677  0.8806   ...      0.5085   3.9763  -0.6260  -0.8544   \n",
       "199978  6.2569  12.7697 -2.1645   ...     -3.8076   3.5345   1.4136   7.5265   \n",
       "199979  6.4800  13.5986  4.0315   ...      6.0298   6.5479   1.1899   2.2901   \n",
       "199980  5.8323  12.1429 -3.1511   ...     -2.8294   3.1563   3.5659   8.0195   \n",
       "199981  5.4601  12.1401  5.1918   ...     11.7834   8.5276   1.8640   3.0752   \n",
       "199982  4.7197  10.7883 -8.1002   ...      8.9002   3.4636   1.7597   0.9145   \n",
       "199983  6.6544  14.1274 -0.4182   ...      2.6351   4.4724   1.9564   5.5905   \n",
       "199984  6.3353  21.5936 -4.0102   ...      0.6067   9.9345   3.0712  -4.1932   \n",
       "199985  5.1614  13.7914 -4.8184   ...     -1.0659   4.2747   1.3472   7.6731   \n",
       "199986  5.6492  16.0449  5.3597   ...     -3.0704   3.9924   2.8872   3.3142   \n",
       "199987  6.0221  11.7757 -0.5163   ...     -0.1123   8.1185   1.3789   9.1349   \n",
       "199988  4.9564  11.4483  2.8938   ...      3.8250   8.3243   1.0464  -0.0645   \n",
       "199989  6.1978  16.4603  4.4421   ...      4.6640   5.6620   1.0286   7.5683   \n",
       "199990  5.0937  17.7960 -3.1050   ...      1.1663   5.4021   1.4266   0.7912   \n",
       "199991  5.6410  21.5338  5.6578   ...     -4.7798   7.4542   4.8159   8.6821   \n",
       "199992  4.7829  14.7163  0.0779   ...      5.1330   4.3740   0.2961  11.8655   \n",
       "199993  4.7563  16.0455  0.4510   ...      5.0961   7.7472   2.8127   6.6012   \n",
       "199994  5.7000  11.0102  4.9089   ...      9.8487  10.0753  -0.4822   7.7094   \n",
       "199995  4.8579  14.7625 -2.7239   ...      2.0544   9.6849   4.6734  -1.3660   \n",
       "199996  5.6888  18.8862  5.0915   ...      5.0071   6.6548   1.8197   2.4104   \n",
       "199997  5.3883  18.3794  1.6603   ...      5.1536   2.6498   2.4937  -0.0637   \n",
       "199998  4.1959  16.8280  5.3208   ...      3.4259   8.5012   2.2713   5.7621   \n",
       "199999  4.8879  14.4892 -0.5902   ...      0.1398   9.2828   1.3601   4.8985   \n",
       "\n",
       "        var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "0       13.7112   2.4669   4.3654  10.7200  15.4722  -8.7197  \n",
       "1       15.5765   0.4773  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2       12.9813   2.1281  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3       15.1874   3.1656   3.9567   9.2295  13.0168  -4.2108  \n",
       "4       19.5542  -0.2860  -5.1612   7.2882  13.9260  -9.1846  \n",
       "5       14.9438  -2.2151  -6.0233   9.8117  17.1127  10.8240  \n",
       "6       17.5010   0.0295   7.7443   9.1509  18.4736   5.1499  \n",
       "7       15.2648  -1.7931   6.5316  10.4855  23.4631   0.7283  \n",
       "8       16.7144   0.1221  -1.4328   9.9207  16.9865  -3.3304  \n",
       "9       15.1425   0.6075  -4.4447   9.5788  15.8146   9.3457  \n",
       "10      23.2482   0.8738   4.6857  10.1361  12.1140  -2.4978  \n",
       "11      18.4518   0.1000  -7.8212   9.2355  15.0721  -7.3475  \n",
       "12      17.6003  -0.7705   6.5424   8.9599  16.9317 -14.0779  \n",
       "13      16.6549   0.4106  -2.1647  10.0379  20.5904   6.0166  \n",
       "14      18.8216  -0.8522  10.3456   8.2077  17.6097  -0.9141  \n",
       "15      22.8224  -0.9325   8.6849  10.2848  17.4932   6.0800  \n",
       "16      20.1087   1.1051   7.7184   9.3406  21.1746  -2.0098  \n",
       "17      21.4898  -0.2385   8.1878   9.3114  23.0545  -2.3171  \n",
       "18      19.2890  -0.0982   7.5500   9.3848  14.4007  11.2567  \n",
       "19      15.0826  -0.2445   2.1377   8.1116  20.5129   5.4945  \n",
       "20      19.9933  -0.6241  11.7708   7.8690  18.1980  -3.7655  \n",
       "21      13.1176   0.0117   9.3434  10.7644  18.0992  -7.6905  \n",
       "22      16.3797  -0.1113   4.3362   9.0132  16.9635   3.2523  \n",
       "23      16.9806   0.1357  13.9872   8.2489  22.4405  -5.4524  \n",
       "24      17.7824  -0.2536   7.3867   7.9695  12.6078   7.3475  \n",
       "25      23.5212   1.3798   7.6392   6.9239  18.6460 -17.7609  \n",
       "26      17.6562   2.1001  -1.5770   8.0712  16.6316   7.8962  \n",
       "27      23.1983  -1.5301   3.9577   8.7277  16.8255 -18.6596  \n",
       "28      18.2102   1.2457   1.9391   8.6899  14.5739  16.2884  \n",
       "29      20.3427   1.1092  15.0418   8.4667  15.1478   6.2962  \n",
       "...         ...      ...      ...      ...      ...      ...  \n",
       "199970  11.4131   0.6650  -5.2401   9.1059  19.3888  -7.6292  \n",
       "199971  15.0869  -0.9276  -0.5783   8.2742  18.2273  -1.0124  \n",
       "199972  15.4298  -1.3178  -9.4033   9.7116  15.5697  -0.7362  \n",
       "199973  21.0475  -2.0668   0.7093   7.8924  16.0279   7.8535  \n",
       "199974  14.8673  -0.4562  13.9675   8.0088  14.3127  -1.2940  \n",
       "199975  14.6021  -3.0392   4.8943   8.7922  19.6428 -24.7859  \n",
       "199976  17.7793   1.1790  -2.0814  10.6610  11.5385 -23.6067  \n",
       "199977  21.5958   0.3250   7.5404  10.0748  16.0592 -14.0012  \n",
       "199978  20.9985   1.7101   7.9362   7.7696  10.9202 -23.5055  \n",
       "199979  17.0941  -0.1193  13.9055   8.3203  13.0791  -5.1262  \n",
       "199980  16.4657   1.9204   7.3301   9.7953  16.9352   0.2655  \n",
       "199981  11.1675  -0.5150  -0.5399   8.1402  19.2653 -30.3989  \n",
       "199982  15.3558   1.3406   4.2422   8.3144  19.3602  -3.0895  \n",
       "199983  13.4550  -1.7590   3.6424   9.2620  14.0587   5.5770  \n",
       "199984  15.1205  -1.0041  -3.9171   9.1933  13.7584   4.3670  \n",
       "199985  19.6489   0.0318   8.7171   8.9479  12.8983   8.3530  \n",
       "199986  22.5225   0.9812   0.1020   8.3441  14.5823   0.7454  \n",
       "199987  16.4063  -0.6592  -0.6248   7.9463  14.1967   9.8560  \n",
       "199988  18.6666   0.6250  -4.3485   9.4572  13.1265  -6.5024  \n",
       "199989  14.6333  -1.2757  -0.3525   8.1526   9.0933   0.8644  \n",
       "199990  20.6181   0.5917  11.6931   9.6883  12.6723 -16.4310  \n",
       "199991  22.1764   0.0088  -1.2475   8.6422  13.7302 -21.5712  \n",
       "199992  16.2761   0.0447  -6.0102  10.3218   8.2577   5.2651  \n",
       "199993  15.3706  -0.4293   6.8485  10.4270  17.4970 -13.0074  \n",
       "199994  21.5594  -1.2662   4.1468   7.6434  13.0871  -4.3982  \n",
       "199995  12.8721   1.2013  -4.6195   9.1568  18.2102   4.8801  \n",
       "199996  18.9037  -0.9337   2.9995   9.1112  18.1740 -20.7689  \n",
       "199997  20.0609  -1.1742  -4.1524   9.1933  11.7905 -22.2762  \n",
       "199998  17.0056   1.1763  -2.3761   8.1079   8.7735  -0.2122  \n",
       "199999  20.0926  -1.3048  -2.5981  10.3378  14.3340  -7.7094  \n",
       "\n",
       "[200000 rows x 201 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fold 0\n",
      "(200000, 201)\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=SEED)\n",
    "oof_preds = np.zeros((len(x_train), 1))\n",
    "test_preds = np.zeros((len(x_test), 1))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, y_train.values)):\n",
    "    x_test=test_df.drop(test_drop_col,axis=1)\n",
    "    print(\"\\n\")\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_x,trn_y = x_train.iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "    val_x,val_y = x_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    new_trn_x,new_val_x,new_x_test=create_kmean(trn_x,val_x,x_test)\n",
    "    #print(new_trn_x)\n",
    "    \n",
    "    trn_data = lgb.Dataset(new_trn_x,trn_y)\n",
    "    val_data = lgb.Dataset(new_val_x,val_y)\n",
    "    \n",
    "    num_round = 1000000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 3000)\n",
    "    val_pred = clf.predict(new_val_x, num_iteration=clf.best_iteration)\n",
    "    test_pred = clf.predict(new_x_test, num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = x_train.columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    print(\"AUC = {}\".format(roc_auc_score(val_y, val_pred)))\n",
    "    #print(\"val = {}\".format(val_pred)\n",
    "    oof_preds[val_idx, :] = val_pred.reshape((-1, 1))\n",
    "    test_preds += test_pred.reshape((-1, 1))\n",
    "    \n",
    "test_preds /= fold_num\n",
    "roc_score = roc_auc_score(y_train, oof_preds.ravel())\n",
    "print(\"Overall AUC = {}\".format(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:150].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../04_predict_test/241_FI.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果保存\n",
    "if (submit_flg ==1 and sampling_flg==0):\n",
    "    series_oof_preds = pd.Series(data=oof_preds[:,0], name=save_col_name, dtype='float')\n",
    "    series_oof_preds.to_csv(train_preds_dir,header=True, index=False)\n",
    "\n",
    "    sample = pd.read_csv(sample_submission_dir)\n",
    "    sample.target = test_preds[:,0].astype(float)\n",
    "    sample.ID_code = test_df['ID_code']\n",
    "    sample.to_csv(test_preds_dir, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
